#!/bin/bash
#PBS -q milanq
#PBS -l select=8:ncpus=128:mpiprocs=1:mem=250gb
#PBS -l place=scatter:excl
#PBS -l walltime=3:00:00
#PBS -joe

# export MPICH_ENV_DISPLAY=1
module load cray-pals # Use CRAY Parallel Application Launch Service

: >"$OUT_FILE"
exec &> >(tee -a "$OUT_FILE")

set -eu

cd "$RUN_DIR" || exit 2
date
echo "$PWD"
ldd "$BENCHMARK_EXE"

NP=$(wc -l $PBS_NODEFILE | awk '{print $1}')
DECK="$PWD/TeaLeaf/Benchmarks/tea_bm_${INPUT_BM}.in"
PROBLEMS="$PWD/TeaLeaf/tea.problems"
NCPUS=$(nproc)

echo "master=$(hostname) nproc=$NCPUS"
echo "mpicc=$(which mpiexec)"
echo "PWD=$PWD"
echo "NP=$NP"
echo "CONFIG=$CONFIG"
echo "BENCHMARK_EXE=$BENCHMARK_EXE"
echo "DECK=$DECK"
echo "======"

mkdir -p ../out

# gdb -batch -ex "run" -ex "bt" --args
# gdb -batch -ex "run" -ex "bt" -ex "quit" --args

opts=""
case "$MODEL" in
sycl-acc)
    # With host task on, staging switches to interop_handle which is OpenCL on CPUs, and we can't handle that
    # with staging on. We revert to get_host_access which probably internally calls clEnqueueMapBuffer so
    # the bahaviour should be the same.
    opts+=" --device 1"
    opts+=" --staging-buffer true"
    ;;
sycl-usm)
    opts+=" --device 1"
    opts+=" --staging-buffer false"
    ;;
tbb | std-* | kokkos | omp)
    opts+=" --staging-buffer false"
    ;; # no-op
*)
    echo "Unknown run configuration for model '$MODEL'"
    exit 1
    ;;
esac

(
    set -o xtrace
    export OMP_NUM_THREADS=128
    export OMP_PROC_BIND=true
    export OMP_PLACES=cores

    export DPCPP_CPU_NUM_CUS=64
    # export DPCPP_CPU_PLACES=sockets
    export DPCPP_CPU_CU_AFFINITY=close
    export DPCPP_CPU_SCHEDULE=static

    for i in $(seq "$NP" -1 1); do
        echo ">>> Using 1R/N $i"
        mpiexec -np "$i" --cpu-bind none --mem-bind none \
            "$BENCHMARK_EXE" --file "$DECK" --problems "$PROBLEMS" --out "../out/tea_np${i}_${CONFIG}_${INPUT_BM}.out" --staging-buffer false $opts
    done
)
(
    set -o xtrace
    export OMP_NUM_THREADS=1
    export OMP_PROC_BIND=true
    export OMP_PLACES=cores

    export DPCPP_CPU_NUM_CUS=1
    export DPCPP_CPU_PLACES=numa_domains
    export DPCPP_CPU_CU_AFFINITY=close
    export DPCPP_CPU_SCHEDULE=static

    for i in $(seq "$((NP * NCPUS))" "-$NCPUS" "$NCPUS"); do
        echo ">>> Using 1R/T $i"
        mpiexec -np "$i" --cpu-bind core --mem-bind local \
            "$BENCHMARK_EXE" --file "$DECK" --problems "$PROBLEMS" --out "../out/tea_np${i}_${CONFIG}_${INPUT_BM}.out" --staging-buffer false $opts
    done
)
